<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Tiny World Model</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Tiny World Model</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Mathew Salvaris</a>
              </span>
                <span class="author-block">
                  
                  
                  </div>

                 

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      

                    <!-- Supplementary PDF link -->
                    

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/msalvaris/tiny_world_model" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/world_model_wbm.webm">
      </video>
      <h2 class="subtitle has-text-centered">
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-dark">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          
          <p>
            World models are prevalent in various applications, from robotics to self-driving cars. 
            They are seen as solutions to many shortcomings of standard modeling approaches and can make reinforcement learning (RL) more sample efficient. 
            However, the models required to process information from camera setups on robots and self-driving cars can be prohibitively expensive.
            Despite this, I wanted to experiment with the concept of world models. So, I created a simple "ball world" where a ball bounces around aimlessly for N frames. 
            The goal is for the model to take the preceding frames as input and predict the next frame, essentially forecasting the ball's next position. 
            Although this is a very basic world to model, it includes the essential components of more complex world models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Architecture</h2>
        <div class="content has-text-justified">
          
          <p>
            The model architecture is quite simple. It features an encoder that takes an image and transforms it into an embedding of size N. 
            Although there are various ways to achieve this, the most common being the use of a Convolutional Neural Network (CNN), 
            I opted for a Multi-Layer Perceptron (MLP) due to the small input dimensionality.

            After encoding the input, M of these encoded inputs are fed into a causal language model. 
            I used a straightforward architecture inspired by Karpathy's GPT. 
            The rationale behind this choice is to show that a task-specific architecture isn't necessary and that Transformers perform exceptionally well in this context. 
            The model's task is to predict the next frame based on the previous M frames, outputting an embedding of size N.

            This embedding is then passed into a decoder, which is mainly an MLP, to generate a 64x64 binary image. This image represents the predicted next state of the "ball world."
          </p>
          <img src="static/images/model_diagram.png" alt="MY ALT TEXT"/>
        </div>


      </div>
    </div>
  </div>
</section>

<section class="section hero is-dark">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset</h2>
        <div class="content has-text-justified">
          
          <p>
            The world model's dataset is generated synthetically using Python. 
            Utilizing the Pillow library, a ball is drawn on a 64x64 canvas, and based on its trajectory and velocity, the ball is redrawn at a new location in each subsequent frame. 
            A total of 1,000 sequences were generated, with each sequence comprising 20 frames. 
            To introduce variation among the sequences, the velocity (ranging from -4 pixels to 4 pixels) and the initial location were uniformly sampled. 
            Out of these sequences, 10% were reserved for validation purposes.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Training</h2>
        <div class="content has-text-justified">
          
          <p>
          
          The training process is kept straightforward, employing a constant learning rate and the AdamW optimizer. 
          The 20-frame sequences are divided into overlapping 5-frame sequences, where the first 4 frames serve as the input, and the final frame serves as the target for the model. 
          The model undergoes approximately 160 epochs of training, which takes around 30 minutes on an A10 GPU.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>









  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->
</body>
</html>
